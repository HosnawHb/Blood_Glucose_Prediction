{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HosnawHb/Blood_Glucose_Prediction/blob/main/MOE_22July.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZcFoHJbL0tT_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "from google.colab import drive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from google.colab import drive\n",
        "import requests\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from keras.layers import Input\n",
        "from keras.layers import SimpleRNN\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.layers import LSTM, BatchNormalization, Bidirectional,GRU\n",
        "from keras.layers import concatenate\n",
        "from keras import Model\n",
        "from keras.models import Sequential\n",
        "import datetime\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import csv\n",
        "import pickle\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "from sklearn.preprocessing import Normalizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIVfL0-c03nD",
        "outputId": "b9ca3e72-5fee-4608-cefe-4665dd89c951"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/dataset/CGM/XPH5\", 'rb') as f:\n",
        "    X = pickle.load(f)"
      ],
      "metadata": {
        "id": "5CsjOfeu1apm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/dataset/CGM/yPH5\", 'rb') as f:\n",
        "    y = pickle.load(f)"
      ],
      "metadata": {
        "id": "rEJZsVb41v91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.reshape(X, (len(X), len(X[1])))\n",
        "y = np.reshape(y, (len(y), 1))"
      ],
      "metadata": {
        "id": "XAcY_Rv210_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, y.shape"
      ],
      "metadata": {
        "id": "cgs5gqLN1-8o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43f7a2d5-0b33-434f-bd4c-6fae8ba6fb33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((118186, 5), (118186, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Normalizer().fit_transform(X, y)"
      ],
      "metadata": {
        "id": "IFBP0bnJhizi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54ade061-3668-4b6e-d6dc-e4241f6198fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.51484397, 0.51220375, 0.49768251, 0.3313483 , 0.33926898],\n",
              "       [0.55729412, 0.54149455, 0.36051759, 0.36913554, 0.36051759],\n",
              "       [0.60119946, 0.40026807, 0.40983624, 0.40026807, 0.38751053],\n",
              "       ...,\n",
              "       [0.42280993, 0.44395043, 0.45099726, 0.4533462 , 0.46391645],\n",
              "       [0.43469473, 0.44159465, 0.44389462, 0.45424449, 0.46114441],\n",
              "       [0.4364541 , 0.4387273 , 0.4489567 , 0.45577629, 0.45577629]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "def splitter(X,y,testPercent):\n",
        "\n",
        "  #Split train and test data\n",
        "\n",
        "  X_train,X_test,y_train,y_test = train_test_split(X, y, test_size= testPercent)\n",
        "  X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2)\n",
        "  return X_train, X_test, y_train, y_test,X_valid, y_valid\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "eSXTtpJW32P6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "920a4526-eee6-4363-ce6e-fa24bde97abe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef splitter(X,y,testPercent):\\n\\n  #Split train and test data\\n  \\n  X_train,X_test,y_train,y_test = train_test_split(X, y, test_size= testPercent)\\n  X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2)\\n  return X_train, X_test, y_train, y_test,X_valid, y_valid\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#X_train,X_test,y_train,y_test,X_valid,y_valid = splitter(X,y,0.1)"
      ],
      "metadata": {
        "id": "2c5iDPZC34wE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.reshape(X, (len(X), len(X[1])))\n",
        "y = np.reshape(y, (len(y), 1))"
      ],
      "metadata": {
        "id": "sLTqbOk3Ab-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.from_numpy(X)\n",
        "y = torch.from_numpy(y)\n",
        "X = X.to(torch.float32)\n",
        "y = y.to(torch.float32)"
      ],
      "metadata": {
        "id": "OIu1yBwr1SKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size= 0.2)"
      ],
      "metadata": {
        "id": "PyjCf3fA-b2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataLoader = DataLoader([ [X_train[i], y_train[i]] for i in range(len(y_train))], shuffle=True, batch_size=32)\n",
        "test_dataLoader = DataLoader([ [X_test[i], y_test[i]] for i in range(len(y_test))], shuffle=True, batch_size=32)"
      ],
      "metadata": {
        "id": "K0J8Fj_x-f1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataLoader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-XibT9O_jJo",
        "outputId": "a8196640-20f9-4332-beb2-acbc9490389e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7fd34fe3e320>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MixtureOfExpertsBard(nn.Module):\n",
        "    def __init__(self,input_size, num_experts, hidden_size, output_size):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_experts = num_experts\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.input_size = input_size\n",
        "\n",
        "        self.experts = nn.ModuleList([\n",
        "            nn.LSTM(input_size=input_size, hidden_size=hidden_size) for _ in range(num_experts)\n",
        "        ])\n",
        "\n",
        "        self.gating_layer = nn.Linear(input_size, num_experts)\n",
        "        self.Linear1 = nn.Linear(hidden_size, 8)\n",
        "        self.Linear2 = nn.Linear(8, 4)\n",
        "        self.Linear3 = nn.Linear(4, 2)\n",
        "        self.output_layer = nn.Linear(2, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Get the outputs of the experts.\n",
        "        expert_outputs = []\n",
        "        for expert in self.experts:\n",
        "          exp , (h1,c1) = expert(x)\n",
        "          #print(\"each exp\", len(exp))\n",
        "          expert_outputs.append(exp)\n",
        "\n",
        "        # Get the gating weights.\n",
        "        expert_outputs = torch.stack(expert_outputs, dim=1)\n",
        "        gating_weights = self.gating_layer(x)\n",
        "        print('gating_weights', gating_weights.shape)\n",
        "        print('expert_outputs',expert_outputs.shape)\n",
        "        # Compute the weighted sum of the expert outputs.\n",
        "        weighted_sum = torch.sum(expert_outputs * gating_weights.view(x.shape[0],self.num_experts) , dim=1)\n",
        "        out = self.Linear1(weighted_sum)\n",
        "        out = self.Linear2(out)\n",
        "        out = self.Linear3(out)\n",
        "        # Output the result.\n",
        "        return self.output_layer(out)\n",
        "model = MixtureOfExpertsBard(5,20,32,1)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFnP8vO4_lp9",
        "outputId": "bd6e2b00-54e0-402d-caf1-91762c5a306c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MixtureOfExpertsBard(\n",
            "  (experts): ModuleList(\n",
            "    (0-19): 20 x LSTM(5, 32)\n",
            "  )\n",
            "  (gating_layer): Linear(in_features=5, out_features=20, bias=True)\n",
            "  (Linear1): Linear(in_features=32, out_features=8, bias=True)\n",
            "  (Linear2): Linear(in_features=8, out_features=4, bias=True)\n",
            "  (Linear3): Linear(in_features=4, out_features=2, bias=True)\n",
            "  (output_layer): Linear(in_features=2, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "LossFuction = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "def train(dataloader, model, LossFuction, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        # Compute prediction error\n",
        "        #print(X.size())\n",
        "        pred = model(X)\n",
        "        loss = torch.sqrt(LossFuction(pred, y))\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ],
      "metadata": {
        "id": "ZCCsU510Bdfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataLoader, model, LossFuction, optimizer)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "DGgzUoSvCzpS",
        "outputId": "0bff2977-311a-4d9b-87d6-16984e44fd27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "gating_weights torch.Size([32, 20])\n",
            "expert_outputs torch.Size([32, 20, 32])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-13e5a54ba2f5>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {t+1}\\n-------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLossFuction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-43-da777e0dd6f8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, LossFuction, optimizer)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# Compute prediction error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m#print(X.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLossFuction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-42-eb8727965ed9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'expert_outputs'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexpert_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# Compute the weighted sum of the expert outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mweighted_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpert_outputs\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgating_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_experts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweighted_sum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (32) must match the size of tensor b (20) at non-singleton dimension 2"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-0skX8IBC2Fy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}